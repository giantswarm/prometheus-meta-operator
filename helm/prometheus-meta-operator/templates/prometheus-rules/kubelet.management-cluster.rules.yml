apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  creationTimestamp: null
  labels:
    {{- include "labels.common" . | nindent 4 }}
    cluster_type: "management_cluster"
  name: kubelet.management-cluster.rules
spec:
  groups:
  - name: kubelet
    rules:
    - alert: KubeletConditionBad
      annotations:
        description: '{{`Kubelet {{ $labels.node }} has status condition {{ $labels.condition }}.`}}'
      expr: kube_node_status_condition{condition=~"DiskPressure|MemoryPressure|OutOfDisk", status="true"} == 1
      for: 10m
      labels:
        area: kaas
        cancel_if_cluster_status_creating: "true"
        cancel_if_cluster_status_deleting: "true"
        cancel_if_cluster_status_updating: "true"
        cancel_if_instance_state_not_running: "true"
        cancel_if_kubelet_down: "true"
        severity: notify
        team: biscuit
        topic: managementcluster
    - alert: KubeletDockerOperationsErrorsTooHigh
      annotations:
        description: '{{`Kubelet ({{ $labels.ip }}) is reporting errors rates while performing Docker {{ $labels.operation_type }} operations.`}}'
      expr: rate(kubelet_docker_operations_errors[5m]) > 1
      for: 10m
      labels:
        area: kaas
        cancel_if_cluster_status_creating: "true"
        cancel_if_cluster_status_deleting: "true"
        cancel_if_cluster_status_updating: "true"
        cancel_if_kubelet_down: "true"
        severity: notify
        team: biscuit
        topic: managementcluster
    - alert: KubeletDockerOperationsLatencyTooHigh
      annotations:
        description: '{{`Kubelet ({{ $labels.ip }}) is taking too long to perform Docker {{ $labels.operation_type }} operations.`}}'
      expr: kubelet_docker_operations_latency_microseconds{quantile="0.9", operation_type!="pull_image"} > 115000000
      for: 10m
      labels:
        area: kaas
        cancel_if_cluster_status_creating: "true"
        cancel_if_cluster_status_deleting: "true"
        cancel_if_cluster_status_updating: "true"
        cancel_if_kubelet_down: "true"
        severity: notify
        team: biscuit
        topic: managementcluster
    - alert: KubeletPLEGLatencyTooHigh
      annotations:
        description: '{{`Kubelet ({{ $labels.ip }}) PLEG latency is too high.`}}'
      expr: histogram_quantile(0.99, sum(rate(kubelet_pleg_relist_duration_seconds_bucket[5m])) by (cluster_id, ip, le)) > 100
      for: 10m
      labels:
        area: kaas
        cancel_if_cluster_status_creating: "true"
        cancel_if_cluster_status_deleting: "true"
        cancel_if_cluster_status_updating: "true"
        cancel_if_kubelet_down: "true"
        severity: notify
        team: biscuit
        topic: managementcluster
